"use strict";(self.webpackChunkpackit_dev=self.webpackChunkpackit_dev||[]).push([[1615],{3905:(e,t,r)=>{r.d(t,{Zo:()=>d,kt:()=>k});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var p=n.createContext({}),l=function(e){var t=n.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},d=function(e){var t=l(e.components);return n.createElement(p.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,p=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=l(r),m=a,k=c["".concat(p,".").concat(m)]||c[m]||u[m]||o;return r?n.createElement(k,i(i({ref:t},d),{},{components:r})):n.createElement(k,i({ref:t},d))}));function k(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=m;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var l=2;l<o;l++)i[l]=r[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},52419:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var n=r(87462),a=(r(67294),r(3905));const o={title:"Cloud databases",authors:"jpopelka"},i=void 0,s={unversionedId:"deployment/distributed-workers/AWS-SQS-RDS",id:"deployment/distributed-workers/AWS-SQS-RDS",title:"Cloud databases",description:"In Distributed workers we realized we need a cloud database",source:"@site/research/deployment/distributed-workers/AWS-SQS-RDS.md",sourceDirName:"deployment/distributed-workers",slug:"/deployment/distributed-workers/AWS-SQS-RDS",permalink:"/research/deployment/distributed-workers/AWS-SQS-RDS",draft:!1,editUrl:"https://github.com/packit/research/tree/main/research/deployment/distributed-workers/AWS-SQS-RDS.md",tags:[],version:"current",frontMatter:{title:"Cloud databases",authors:"jpopelka"},sidebar:"autogenerated",previous:{title:"Distributed workers",permalink:"/research/deployment/distributed-workers/"},next:{title:"Deployment and testing strategies",permalink:"/research/deployment/verification"}},p={},l=[{value:"Simple Queue Service - SQS",id:"simple-queue-service---sqs",level:2},{value:"RDS",id:"rds",level:2},{value:"Status",id:"status",level:2}],d={toc:l},c="wrapper";function u(e){let{components:t,...r}=e;return(0,a.kt)(c,(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In ",(0,a.kt)("a",{parentName:"p",href:"/research/deployment/distributed-workers"},"Distributed workers")," we realized we need a cloud database\nin order to be able to have workers in a private cloud (PSI)."),(0,a.kt)("p",null,"Since we already have AWS account (log in with your kerberos credentials\n",(0,a.kt)("a",{parentName:"p",href:"https://auth.redhat.com/auth/realms/EmployeeIDP/protocol/saml/clients/itaws"},"here"),")\nwe decided to use RDS PostgreSQL as database and SQS as Celery broker."),(0,a.kt)("h2",{id:"simple-queue-service---sqs"},"Simple Queue Service - ",(0,a.kt)("a",{parentName:"h2",href:"https://console.aws.amazon.com/sqs/home"},"SQS")),(0,a.kt)("p",null,"At the moment we use only one Celery queue (default, named ",(0,a.kt)("inlineCode",{parentName:"p"},"celery"),") per packit service deployment.\nWith ",(0,a.kt)("inlineCode",{parentName:"p"},"redis")," instance (separate one per deployment) as a broker,\neach deployment has its separate ",(0,a.kt)("inlineCode",{parentName:"p"},"celery")," queue.\nBut with SQS the deployments (",(0,a.kt)("inlineCode",{parentName:"p"},"prod")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"stg"),") can't both use ",(0,a.kt)("inlineCode",{parentName:"p"},"celery")," queue, so we use\n",(0,a.kt)("inlineCode",{parentName:"p"},"packit-$DEPLOYMENT-")," prefix in order to have ",(0,a.kt)("inlineCode",{parentName:"p"},"packit-prod-celery")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"packit-stg-celery")," queues.\nThey are Standard type (best-effort ordering). FIFO would probably be better\nsince it's not OK when for example 'build finished' event is processed before 'build started',\nbut FIFO queue costs more and Celery uses by default Standard type so let's start with it.\nThe queues can be accessed (send to, receive from) only by our packit user.\nOther than that (and proper Tags) they're configured with default values."),(0,a.kt)("h2",{id:"rds"},(0,a.kt)("a",{parentName:"h2",href:"https://console.aws.amazon.com/rds/home"},"RDS")),(0,a.kt)("p",null,"For ",(0,a.kt)("inlineCode",{parentName:"p"},"stg")," (there's no DB for ",(0,a.kt)("inlineCode",{parentName:"p"},"prod")," atm) we have a ",(0,a.kt)("inlineCode",{parentName:"p"},"db.t3.micro")," (cheapest/slowest)\nclass PostgreSQL (11.x) DB in ",(0,a.kt)("inlineCode",{parentName:"p"},"default")," VPC with ",(0,a.kt)("inlineCode",{parentName:"p"},"public-all")," security group.\nFor ",(0,a.kt)("inlineCode",{parentName:"p"},"prod")," db we might investigate restricting it so that it could be accessed\nonly from Openshift cluster(s) we use.\nTo import data from our local ",(0,a.kt)("inlineCode",{parentName:"p"},"postgres")," instance to RDS:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"oc rsh postgres-1-r2vnd pg_dump -v -U <user> -d <db name> -f /tmp/packit.dump\noc rsync postgres-1-r2vnd:/tmp/packit.dump ./\npsql -f packit.dump --host packit-stg.abcxyz.region.rds.amazonaws.com --username <user> --password --dbname <db name>\n")),(0,a.kt)("h2",{id:"status"},"Status"),(0,a.kt)("p",null,"At the moment of writing this only ",(0,a.kt)("inlineCode",{parentName:"p"},"stg")," uses ",(0,a.kt)("inlineCode",{parentName:"p"},"SQS")," & ",(0,a.kt)("inlineCode",{parentName:"p"},"RDS"),",\n",(0,a.kt)("inlineCode",{parentName:"p"},"prod")," still runs its own ",(0,a.kt)("inlineCode",{parentName:"p"},"redis")," & ",(0,a.kt)("inlineCode",{parentName:"p"},"postgres"),".\nSo far ",(0,a.kt)("inlineCode",{parentName:"p"},"stg")," seems to be running OK with it and ",(0,a.kt)("inlineCode",{parentName:"p"},"redis")," & ",(0,a.kt)("inlineCode",{parentName:"p"},"postgres")," turned off.\nThe downside we've noticed is that dashboard is several times slower\n(due to the DB instance class we use).\nAlso we\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/packit/deployment/pull/135"},"can't use readiness and liveness probes for workers"),"."),(0,a.kt)("p",null,"I also temporarily deployed one packit worker in our cyborg-stage project @ PSI.\nI proved that it was accepting tasks from AWS SQS and tore it down again.\nI saw no backend related error so I believe it was able to connect to AWS RDS PostgreSQL as well.\nTo make it build (S)RPMS I'd need a separate sandbox project there which I don't have atm."),(0,a.kt)("p",null,"(jpopelka, September 2020)"))}u.isMDXComponent=!0}}]);