"use strict";(self.webpackChunkpackit_dev=self.webpackChunkpackit_dev||[]).push([[1486],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>f});var a=r(67294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function n(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function l(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?n(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):n(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,a,o=function(e,t){if(null==e)return{};var r,a,o={},n=Object.keys(e);for(a=0;a<n.length;a++)r=n[a],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)r=n[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var i=a.createContext({}),c=function(e){var t=a.useContext(i),r=t;return e&&(r="function"==typeof e?e(t):l(l({},t),e)),r},p=function(e){var t=c(e.components);return a.createElement(i.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var r=e.components,o=e.mdxType,n=e.originalType,i=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(r),h=o,f=u["".concat(i,".").concat(h)]||u[h]||d[h]||n;return r?a.createElement(f,l(l({ref:t},p),{},{components:r})):a.createElement(f,l({ref:t},p))}));function f(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var n=r.length,l=new Array(n);l[0]=h;var s={};for(var i in t)hasOwnProperty.call(t,i)&&(s[i]=t[i]);s.originalType=e,s[u]="string"==typeof e?e:o,l[1]=s;for(var c=2;c<n;c++)l[c]=r[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,r)}h.displayName="MDXCreateElement"},17305:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>i,contentTitle:()=>l,default:()=>d,frontMatter:()=>n,metadata:()=>s,toc:()=>c});var a=r(87462),o=(r(67294),r(3905));const n={title:"Airflow",authors:"lbarcziova"},l=void 0,s={unversionedId:"workflow-engines/airflow",id:"workflow-engines/airflow",title:"Airflow",description:"- docs//airflow.apache.org/docs/apache-airflow/stable/index.html",source:"@site/research/workflow-engines/airflow.md",sourceDirName:"workflow-engines",slug:"/workflow-engines/airflow",permalink:"/research/workflow-engines/airflow",draft:!1,editUrl:"https://github.com/packit/research/tree/main/research/workflow-engines/airflow.md",tags:[],version:"current",frontMatter:{title:"Airflow",authors:"lbarcziova"},sidebar:"autogenerated",previous:{title:"Workflow engines",permalink:"/research/workflow-engines/"},next:{title:"Argo Workflows",permalink:"/research/workflow-engines/argo-workflows"}},i={},c=[{value:"CeleryExecutor",id:"celeryexecutor",level:2},{value:"CeleryKubernetesExecutor",id:"celerykubernetesexecutor",level:2},{value:"KubernetesExecutor",id:"kubernetesexecutor",level:2},{value:"Deployment",id:"deployment",level:2}],p={toc:c},u="wrapper";function d(e){let{components:t,...r}=e;return(0,o.kt)(u,(0,a.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"docs: ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/index.html"},"https://airflow.apache.org/docs/apache-airflow/stable/index.html")),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"Apache Airflow is a platform used to programmatically author, schedule, and monitor workflows. It allows you to define complex workflows as directed acyclic graphs (DAGs) and execute them on a scheduled basis or triggered by events."))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"A DAG is the core concept in Airflow. It's a collection of tasks and their dependencies, organized as a directed acyclic graph. Example:"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"from datetime import datetime\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\ndef build_task():\n    pass\n\ndef test_task():\n    pass\n\ndef dynamic_workflow():\n    dag = DAG(\n        f'dynamic_workflow',\n        start_date=datetime.now(),\n        schedule_interval=None,\n        catchup=False,\n    )\n\n    build = PythonOperator(\n        task_id=f'build',\n        python_callable=build_task,\n        op_args=[],\n        dag=dag,\n    )\n\n    test = PythonOperator(\n        task_id=f'test',\n        python_callable=test_task,\n        op_args=[],\n        dag=dag,\n    )\n\n    # Set task dependencies\n    build >> test\n\n    return dag\n\ndynamic_workflow()\n\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Airflow uses schedulers and executors to manage task execution. The scheduler determines when to execute tasks,\nwhile the executor defines how tasks are run.",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Airflow supports various executors:"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/index.html#executor-types"},"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/index.html#executor-types"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"local ones: e.g. SequentialExecutor, LocalExecutor"),(0,o.kt)("li",{parentName:"ul"},"remote ones: e.g. CeleryExecutor, CeleryKubernetesExecutor, KubernetesExecutor"))))),(0,o.kt)("li",{parentName:"ul"},"allows dynamic pipelines generation"),(0,o.kt)("li",{parentName:"ul"},"sensors: type of operators designed to wait for something to occur:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/sensors.html"},"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/sensors.html"),(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"It can be time-based, or waiting for a file, or an external event, but all they do is wait until something happens, and then succeed so their downstream tasks can run."))),(0,o.kt)("li",{parentName:"ul"},"these look like a good fit for waiting for a message from messaging bus"))),(0,o.kt)("li",{parentName:"ul"},"provides UI ",(0,o.kt)("img",{parentName:"li",src:"https://airflow.apache.org/docs/apache-airflow/stable/_images/dags.png",alt:"UI"})),(0,o.kt)("li",{parentName:"ul"},"from ",(0,o.kt)("inlineCode",{parentName:"li"},"Why not")," in docs:",(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"Airflow\u2122 was built for finite batch workflows. While the CLI and REST API do allow triggering workflows, Airflow was not built for infinitely running event-based workflows. Airflow is not a streaming solution. However, a streaming system such as Apache Kafka is often seen working together with Apache Airflow. Kafka can be used for ingestion and processing in real-time, event data is written to a storage location, and Airflow periodically starts a workflow processing a batch of data.")))),(0,o.kt)("h2",{id:"celeryexecutor"},"CeleryExecutor"),(0,o.kt)("p",null,"Details: ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery.html"},"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery.html")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"it is also possible to use Flower UI")),(0,o.kt)("h2",{id:"celerykubernetesexecutor"},"CeleryKubernetesExecutor"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"allows users to run simultaneously a CeleryExecutor and a KubernetesExecutor. An executor is chosen to run a\ntask based on the task\u2019s queue.")),(0,o.kt)("p",null,"Details: ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery_kubernetes.html"},"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery_kubernetes.html"),"\n(also see the section ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/celery_kubernetes.html#when-to-use-celerykubernetesexecutor"},"when to use"),")"),(0,o.kt)("h2",{id:"kubernetesexecutor"},"KubernetesExecutor"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"each task run in its own pod"),(0,o.kt)("li",{parentName:"ul"},"scheduler itself does not necessarily need to be running on Kubernetes, but does need access to a Kubernetes cluster")),(0,o.kt)("p",null,"Details: ",(0,o.kt)("a",{parentName:"p",href:"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/kubernetes.html"},"https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/executor/kubernetes.html")),(0,o.kt)("h2",{id:"deployment"},"Deployment"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"the architecture is more complex, there are multiple components: scheduler, webserver, executor, db, .."),(0,o.kt)("li",{parentName:"ul"},"example of running in Docker: ",(0,o.kt)("a",{parentName:"li",href:"https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html"},"https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html")),(0,o.kt)("li",{parentName:"ul"},"production deployment: ",(0,o.kt)("a",{parentName:"li",href:"https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/production-deployment.html"},"https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/production-deployment.html"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"provides Docker images: ",(0,o.kt)("a",{parentName:"li",href:"https://airflow.apache.org/docs/docker-stack/index.html"},"https://airflow.apache.org/docs/docker-stack/index.html")),(0,o.kt)("li",{parentName:"ul"},"provides Helm charts")))))}d.isMDXComponent=!0}}]);